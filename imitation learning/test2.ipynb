{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DIAMBRAROMSPATH\"] = os.getcwd() \n",
    "os.environ[\"DIAMBRA_ENVS\"] =  \" \".join([f\"\"\"127.0.0.1:{50051 + i}\"\"\" for i in range(1)])\n",
    "import diambra\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from diambra.arena.stable_baselines3.make_sb3_env import make_sb3_env, EnvironmentSettings\n",
    "from diambra.arena import EnvironmentSettings, WrappersSettings\n",
    "from stable_baselines3 import DQN\n",
    "from diambra.arena import SpaceTypes\n",
    "from diambra.arena import Roles, SpaceTypes, load_settings_flat_dict\n",
    "import yaml\n",
    "import json\n",
    "def build_env(params, train : bool = True, render_mode=None):\n",
    "    params[\"settings\"][\"action_space\"] = SpaceTypes.DISCRETE if params[\"settings\"][\"action_space\"] == \"discrete\" else SpaceTypes.MULTI_DISCRETE\n",
    "    settings = load_settings_flat_dict(EnvironmentSettings, params[\"settings\"])\n",
    "    # Wrappers Settings\n",
    "    wrappers_settings = load_settings_flat_dict(WrappersSettings, params[\"wrappers_settings\"])\n",
    "    # Create environment\n",
    "    env, _ = make_sb3_env(\"sfiii3n\", settings, wrappers_settings, render_mode=render_mode, no_vec=True)\n",
    "    return env\n",
    "\n",
    "def load_config(cfg_file):\n",
    "    # Read the cfg file\n",
    "    yaml_file = open(cfg_file)\n",
    "    params = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "    print(\"Config parameters = \", json.dumps(params, sort_keys=True, indent=4))\n",
    "    yaml_file.close()\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:diambra.arena.engine.interface:Trying to connect to DIAMBRA Engine server (timeout=600s)...\n",
      "INFO:diambra.arena.engine.interface:... done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config parameters =  {\n",
      "    \"folders\": {\n",
      "        \"model_name\": \"sr6_128x4_das_nc\",\n",
      "        \"parent_dir\": \"./results/\"\n",
      "    },\n",
      "    \"policy_kwargs\": {\n",
      "        \"net_arch\": [\n",
      "            64,\n",
      "            64\n",
      "        ]\n",
      "    },\n",
      "    \"ppo_settings\": {\n",
      "        \"autosave_freq\": 256,\n",
      "        \"batch_size\": 256,\n",
      "        \"clip_range\": [\n",
      "            0.15,\n",
      "            0.025\n",
      "        ],\n",
      "        \"gamma\": 0.94,\n",
      "        \"learning_rate\": [\n",
      "            0.00025,\n",
      "            2.5e-06\n",
      "        ],\n",
      "        \"model_checkpoint\": \"0\",\n",
      "        \"n_epochs\": 4,\n",
      "        \"n_steps\": 128,\n",
      "        \"time_steps\": 10000000\n",
      "    },\n",
      "    \"settings\": {\n",
      "        \"action_space\": \"discrete\",\n",
      "        \"characters\": \"Ryu\",\n",
      "        \"continue_game\": 0.0,\n",
      "        \"difficulty\": 6,\n",
      "        \"frame_shape\": [\n",
      "            128,\n",
      "            128,\n",
      "            1\n",
      "        ],\n",
      "        \"game_id\": \"sfiii3n\",\n",
      "        \"outfits\": 2,\n",
      "        \"step_ratio\": 6\n",
      "    },\n",
      "    \"wrappers_settings\": {\n",
      "        \"add_last_action\": true,\n",
      "        \"dilation\": 1,\n",
      "        \"exclude_image_scaling\": true,\n",
      "        \"filter_keys\": [\n",
      "            \"action\",\n",
      "            \"own_health\",\n",
      "            \"opp_health\",\n",
      "            \"own_side\",\n",
      "            \"opp_side\",\n",
      "            \"opp_character\",\n",
      "            \"stage\",\n",
      "            \"timer\"\n",
      "        ],\n",
      "        \"flatten\": true,\n",
      "        \"no_attack_buttons_combinations\": true,\n",
      "        \"normalize_reward\": true,\n",
      "        \"role_relative\": true,\n",
      "        \"scale\": true,\n",
      "        \"stack_actions\": 12,\n",
      "        \"stack_frames\": 4\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:diambra.arena.arena_gym:EnvironmentSettings(game_id='sfiii3n', frame_shape=(128, 128, 1), step_ratio=6, disable_keyboard=True, disable_joystick=True, render_mode=None, splash_screen=True, rank=0, env_address='127.0.0.1:50051', grpc_timeout=600, seed=1732531984, difficulty=6, continue_game=0.0, show_final=False, tower=3, _last_seed=1732531984, pb_model=game_id: \"sfiii3n\"\n",
      "frame_shape {\n",
      "  h: 128\n",
      "  w: 128\n",
      "  c: 1\n",
      "}\n",
      "step_ratio: 6\n",
      "n_players: 1\n",
      "disable_keyboard: true\n",
      "disable_joystick: true\n",
      "action_spaces: DISCRETE\n",
      "episode_settings {\n",
      "}\n",
      ", n_players=1, action_space=1, role=None, characters='Ryu', outfits=2, super_art=None, fighting_style=None, ultimate_style=None, speed_mode=None)\n"
     ]
    }
   ],
   "source": [
    "cfgFile = \"/home/chenningcong/Desktop/sfiii/agents/stable_baselines3/cfg_files/sfiii3n/sr6_128x4_das_nc.yaml\"\n",
    "env = build_env(load_config(cfgFile), True, render_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imitation.algorithms import bc\n",
    "from imitation.data import rollout\n",
    "from imitation.data.wrappers import RolloutInfoWrapper\n",
    "from imitation.policies.serialize import load_policy\n",
    "from imitation.util.util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenningcong/miniconda3/envs/myenv/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object learning_rate. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n",
      "/home/chenningcong/miniconda3/envs/myenv/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n",
      "/home/chenningcong/miniconda3/envs/myenv/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object clip_range_vf. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n",
      "/home/chenningcong/miniconda3/envs/myenv/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code() argument 13 must be str, not int\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "trainedModel = \"/home/chenningcong/Desktop/sfiii/agents/stable_baselines3/results/sfiii3n/sr6_128x4_das_nc/model/model.zip\"\n",
    "agent = PPO.load(trainedModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Monitor<FlattenFilterDictObs<RoleRelativeObservation<NormalizeObservation<ActionsStack<AddLastActionToObservation<FrameStack<NoAttackButtonsCombinations<NormalizeReward<DiambraGym1P instance>>>>>>>>>>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating -1.1677018633540373\n",
      "evaluating -1.1055900621118009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     rrs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(rrs)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(rrs), np\u001b[38;5;241m.\u001b[39mstd(rrs)\n\u001b[0;32m---> 35\u001b[0m \u001b[43mtest_agent_episodic\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_episode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[53], line 31\u001b[0m, in \u001b[0;36mtest_agent_episodic\u001b[0;34m(env, agent, deterministic, seed, preprocess, n_episode)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_agent_episodic\u001b[39m(env, agent, deterministic, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, preprocess\u001b[38;5;241m=\u001b[39mpreprocess, n_episode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m     rrs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mtest_agent_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_episode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     32\u001b[0m     rrs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(rrs)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(rrs), np\u001b[38;5;241m.\u001b[39mstd(rrs)\n",
      "Cell \u001b[0;32mIn[53], line 31\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_agent_episodic\u001b[39m(env, agent, deterministic, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, preprocess\u001b[38;5;241m=\u001b[39mpreprocess, n_episode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m     rrs \u001b[38;5;241m=\u001b[39m [\u001b[43mtest_agent_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_episode)]\n\u001b[1;32m     32\u001b[0m     rrs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(rrs)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(rrs), np\u001b[38;5;241m.\u001b[39mstd(rrs)\n",
      "Cell \u001b[0;32mIn[53], line 15\u001b[0m, in \u001b[0;36mtest_agent_episode\u001b[0;34m(env, agent, seed, deterministic)\u001b[0m\n\u001b[1;32m     12\u001b[0m env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Action random sampling\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m actions, _state \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Environment stepping\u001b[39;00m\n\u001b[1;32m     17\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28mint\u001b[39m(actions))\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:556\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    538\u001b[0m     observation: Union[np\u001b[38;5;241m.\u001b[39mndarray, Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    542\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[1;32m    543\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/stable_baselines3/common/policies.py:352\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03mGet the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03mIncludes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m    (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# Switch to eval mode (this affects batch norm / dropout)\u001b[39;00m\n\u001b[0;32m--> 352\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_training_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;66;03m# Check for common mistake that the user does not mix Gym/VecEnv API\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;66;03m# Tuple obs are not supported by SB3, so we can safely do that check\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(observation) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/stable_baselines3/common/policies.py:211\u001b[0m, in \u001b[0;36mBaseModel.set_training_mode\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_training_mode\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    Put the policy in either training or evaluation mode.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    :param mode: if true, set to training mode, else set to evaluation mode\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:2454\u001b[0m, in \u001b[0;36mModule.train\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mode, \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m   2453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining mode is expected to be boolean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2454\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m   2455\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m   2456\u001b[0m     module\u001b[38;5;241m.\u001b[39mtrain(mode)\n",
      "File \u001b[0;32m~/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1740\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1738\u001b[0m                 d\u001b[38;5;241m.\u001b[39mdiscard(name)\n\u001b[0;32m-> 1740\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Parameter):\n\u001b[1;32m   1742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import time\n",
    "def test_agent_episode(env, agent, seed=42, deterministic : bool=False):   \n",
    "    # Environment reset\n",
    "    observation = env.reset()[0]\n",
    "    # Agent-Environment interaction loop\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        # (Optional) Environment rendering\n",
    "        env.render()\n",
    "        \n",
    "        # Action random sampling\n",
    "        actions, _state = agent.predict(observation, deterministic=False)\n",
    "        # Environment stepping\n",
    "        observation, reward, terminated, truncated, info = env.step(int(actions))\n",
    "        total_reward += reward\n",
    "        # Episode end (Done condition) check\n",
    "        if terminated or truncated:\n",
    "            observation = env.reset()\n",
    "            break\n",
    "\n",
    "    # # Environment shutdown\n",
    "    # env.close()\n",
    "    print(f\"evaluating {total_reward}\")\n",
    "    # Return success\n",
    "    return total_reward\n",
    "\n",
    "def test_agent_episodic(env, agent, deterministic, seed=42, preprocess=preprocess, n_episode=1):\n",
    "    rrs = [test_agent_episode(env, agent, seed, preprocess) for i in range(n_episode)]\n",
    "    rrs = np.array(rrs)\n",
    "    return np.mean(rrs), np.std(rrs)\n",
    "\n",
    "test_agent_episodic(env, agent, deterministic=False, seed=42, n_episode=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
